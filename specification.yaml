action: training/inference
data: ../archive/test.csv # This will be taken from data warehouse
model: svm/random_forest/etc
data_preprocessing:
  tokenization: [0, 1, 2] # column numbers
  to_lowercase: [0, 1, 2]
  remove_nonalphanumerics: [0, 1, 2]
  remove_stopwords: [0, 1, 2]
  lemmatization: [0, 1, 2]
  stemming: [0, 1, 2]
  remove_specific:
    regex: some_regex
    columns: [0, 1, 2]
feature_extraction:
  # the columns must be mutually exclusive in these techniques
  drop: [0, 1, 2]
  TF_IDF: [0, 1, 2] # column numbers
  one_hot_encoding: [0, 1, 2]
  bag_of_words: [0, 1, 2]
  n_grams: [0, 1, 2]
  word_2_vec: [0, 1, 2]
training:
  features: ["feature-1", "feature-2"] # column names
  labels: ["label-1", "label-2"] # column names
  learning_rate: 0.1
  batch_size: 300
  epochs: 5
  n_estimators: 100
  max_depth: 20
  cross_validation_frequency: 5
  use_grid_search: true
  train_test_val_split: 60/20/20

# more options can be added as per requirement and these options are not compulsory to give in the YAML file,
# if they are there, our backend will process them otherwise the task will not occur.