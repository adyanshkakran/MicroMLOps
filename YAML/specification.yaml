action: training/inference
data: ../archive/test.csv # This will be taken from data warehouse
model: svm/random_forest/etc
data_preprocessing:
  tokenization: ["column-1", "column-2"] # column names
  to_lowercase: ["column-1", "column-2"]
  remove_nonalphanumerics: ["column-1", "column-2"]
  remove_stopwords: ["column-1", "column-2"]
  lemmatization: ["column-1", "column-2"]
  stemming: ["column-1", "column-2"]
  remove_specific:
    regex: some_regex
    columns: ["column-1", "column-2"]
feature_extraction:
  # the columns must be mutually exclusive in these techniques
  drop: ["column-1", "column-2"]
  TF_IDF: ["column-1", "column-2"] # column names
  one_hot_encoding: ["column-1", "column-2"]
  bag_of_words: ["column-1", "column-2"]
training:
  features: ["feature-1", "feature-2"] # column names
  labels: ["label-1", "label-2"] # column names
  learning_rate: 0.1
  batch_size: 300
  epochs: 5
  n_estimators: 100
  max_depth: 20
  cross_validation_frequency: 5
  use_grid_search: true
  train_test_val_split: 60/20/20

# more options can be added as per requirement and these options are not compulsory to give in the YAML file,
# if they are there, our backend will process them otherwise the task will not occur.